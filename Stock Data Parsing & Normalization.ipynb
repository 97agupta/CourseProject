{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date Contract  Units  $Volume  LowPrice  HighPrice  AvgPrice  \\\n",
      "0   05/01/00      Dem    224  112.043     0.490      0.550     0.500   \n",
      "1   05/01/00   Reform      2    0.067     0.019      0.048     0.034   \n",
      "2   05/01/00      Rep    116   57.950     0.488      0.501     0.500   \n",
      "3   05/02/00      Dem     87   44.369     0.501      0.522     0.510   \n",
      "4   05/02/00   Reform     50    0.196     0.003      0.005     0.004   \n",
      "..       ...      ...    ...      ...       ...        ...       ...   \n",
      "88  05/30/00   Reform     53    0.318     0.006      0.006     0.006   \n",
      "89  05/30/00      Rep    249  126.944     0.504      0.510     0.510   \n",
      "90  05/31/00      Dem    252  126.890     0.492      0.514     0.504   \n",
      "91  05/31/00   Reform    115    0.445     0.003      0.004     0.004   \n",
      "92  05/31/00      Rep     67   33.803     0.495      0.507     0.505   \n",
      "\n",
      "    LastPrice  \n",
      "0       0.550  \n",
      "1       0.019  \n",
      "2       0.500  \n",
      "3       0.508  \n",
      "4       0.003  \n",
      "..        ...  \n",
      "88      0.006  \n",
      "89      0.510  \n",
      "90      0.492  \n",
      "91      0.003  \n",
      "92      0.497  \n",
      "\n",
      "[93 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "import seaborn as sns\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from dateutil.parser import parse\n",
    "from scipy import signal\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy import stats\n",
    "from statsmodels.tsa.stattools import adfuller, kpss, acf, pacf, grangercausalitytests\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "df_collection = {}\n",
    "\n",
    "dfs_may = pd.read_html('stock_data/May_2000.htm', header =0)\n",
    "df_collection['May'] = pd.DataFrame(dfs_may[0])\n",
    "dfs_june = pd.read_html('stock_data/June_2000.htm', header =0)\n",
    "df_collection['June'] = dfs_june[0]\n",
    "dfs_july = pd.read_html('stock_data/July_2000.htm', header =0)\n",
    "df_collection['July'] = dfs_july[0]\n",
    "dfs_august = pd.read_html('stock_data/August_2000.htm', header =0)\n",
    "df_collection['Aug'] = dfs_august[0]\n",
    "dfs_sept = pd.read_html('stock_data/Sept_2000.htm', header =0)\n",
    "df_collection['Sept'] = dfs_sept[0]\n",
    "dfs_oct = pd.read_html('stock_data/Oct_2000.htm', header =0)\n",
    "df_collection['Oct'] = dfs_oct[0]\n",
    "\n",
    "print((df_collection['May']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_collection:\n",
    "    df = df_collection[key]\n",
    "    df_collection[key] = df_collection[key][df_collection[key].Contract != 'Reform']\n",
    "    df_collection[key] = df_collection[key].drop(['Units','$Volume','LowPrice','HighPrice','LastPrice'], axis = 1)\n",
    "    df_collection[key] = df_collection[key].dropna()\n",
    "    df_collection[key]['NormalizedPrice'] = 0\n",
    "    \n",
    "    for index,row in df_collection[key].iterrows():\n",
    "        if(row['Contract'] == 'Dem'):\n",
    "            demPrice = float(row['AvgPrice'])\n",
    "            #print(demPrice)\n",
    "            repPrice = df_collection[key].loc[df_collection[key]['Date'] == row['Date']]\n",
    "            repPrice = repPrice[repPrice.Contract != 'Dem']\n",
    "            repPrice.reset_index(drop=True, inplace=True)\n",
    "            if(repPrice.empty):\n",
    "                df_collection[key].loc[index,'NormalizedPrice'] = -1\n",
    "            else:\n",
    "                repPrice = repPrice.iloc[0]['AvgPrice']\n",
    "                repPrice = float(repPrice)\n",
    "                df_collection[key].loc[index,'NormalizedPrice'] = demPrice / (demPrice+repPrice)\n",
    "        if(row['Contract'] == 'Rep'):\n",
    "            repPrice = float(row['AvgPrice'])\n",
    "            #print(demPrice)\n",
    "            demPrice = df_collection[key].loc[df_collection[key]['Date'] == row['Date']]\n",
    "            demPrice = demPrice[demPrice.Contract != 'Rep']\n",
    "            demPrice.reset_index(drop=True, inplace=True)\n",
    "            if(demPrice.empty):\n",
    "                df_collection[key].loc[index,'NormalizedPrice'] = -1\n",
    "            else:\n",
    "                demPrice = demPrice.loc[0,'AvgPrice']\n",
    "                demPrice = float(demPrice)\n",
    "                df_collection[key].loc[index,'NormalizedPrice'] = repPrice / (demPrice+repPrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Contract</th>\n",
       "      <th>AvgPrice</th>\n",
       "      <th>NormalizedPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05/01/00</td>\n",
       "      <td>Dem</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05/01/00</td>\n",
       "      <td>Rep</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05/02/00</td>\n",
       "      <td>Dem</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.507463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>05/02/00</td>\n",
       "      <td>Rep</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.492537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>05/03/00</td>\n",
       "      <td>Dem</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.508492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>10/29/00</td>\n",
       "      <td>Rep</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.670647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>10/30/00</td>\n",
       "      <td>Dem</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.352475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>10/30/00</td>\n",
       "      <td>Rep</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.647525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>10/31/00</td>\n",
       "      <td>Dem</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.382530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>10/31/00</td>\n",
       "      <td>Rep</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.617470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>349 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Contract  AvgPrice  NormalizedPrice\n",
       "0   05/01/00      Dem     0.500         0.500000\n",
       "2   05/01/00      Rep     0.500         0.500000\n",
       "3   05/02/00      Dem     0.510         0.507463\n",
       "5   05/02/00      Rep     0.495         0.492537\n",
       "6   05/03/00      Dem     0.509         0.508492\n",
       "..       ...      ...       ...              ...\n",
       "86  10/29/00      Rep     0.674         0.670647\n",
       "87  10/30/00      Dem     0.356         0.352475\n",
       "89  10/30/00      Rep     0.654         0.647525\n",
       "90  10/31/00      Dem     0.381         0.382530\n",
       "92  10/31/00      Rep     0.615         0.617470\n",
       "\n",
       "[349 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = []\n",
    "for key in df_collection:\n",
    "    frames.append(df_collection[key])\n",
    "    \n",
    "df_all_normalized = pd.concat(frames)\n",
    "df_all_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date     topic  probability\n",
      "0    05/03/00    warner     0.008921\n",
      "1    05/04/00    connor     0.005673\n",
      "2    05/05/00      bush     0.006957\n",
      "3    05/02/00     cable     0.010275\n",
      "4    05/20/00  giuliani     0.014083\n",
      "..        ...       ...          ...\n",
      "179  06/12/00      code     0.006021\n",
      "180  06/13/00     court     0.010863\n",
      "181  06/14/00     court     0.013246\n",
      "182  06/22/00      drug     0.005958\n",
      "183  06/25/00  saturday     0.003432\n",
      "\n",
      "[184 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df_plsa = pd.read_csv ('plsa.csv')\n",
    "print(df_plsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = df_plsa.topic.unique()\n",
    "\n",
    "df_topics_collection = {} \n",
    "\n",
    "for topic in topics:\n",
    "    df_topics_collection[topic] = df_plsa.loc[df_plsa['topic'] == topic]\n",
    "\n",
    "#print(df_topics_collection[topics[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.8525  , p=0.3617  , df_denom=38, df_num=1\n",
      "ssr based chi2 test:   chi2=0.9198  , p=0.3375  , df=1\n",
      "likelihood ratio test: chi2=0.9096  , p=0.3402  , df=1\n",
      "parameter F test:         F=0.8525  , p=0.3617  , df_denom=38, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=0.2803  , p=0.7573  , df_denom=35, df_num=2\n",
      "ssr based chi2 test:   chi2=0.6406  , p=0.7259  , df=2\n",
      "likelihood ratio test: chi2=0.6356  , p=0.7278  , df=2\n",
      "parameter F test:         F=0.2803  , p=0.7573  , df_denom=35, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=0.2918  , p=0.8310  , df_denom=32, df_num=3\n",
      "ssr based chi2 test:   chi2=1.0668  , p=0.7851  , df=3\n",
      "likelihood ratio test: chi2=1.0525  , p=0.7886  , df=3\n",
      "parameter F test:         F=0.2918  , p=0.8310  , df_denom=32, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=0.1406  , p=0.9657  , df_denom=29, df_num=4\n",
      "ssr based chi2 test:   chi2=0.7371  , p=0.9467  , df=4\n",
      "likelihood ratio test: chi2=0.7300  , p=0.9476  , df=4\n",
      "parameter F test:         F=0.1406  , p=0.9657  , df_denom=29, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=0.0888  , p=0.9933  , df_denom=26, df_num=5\n",
      "ssr based chi2 test:   chi2=0.6317  , p=0.9865  , df=5\n",
      "likelihood ratio test: chi2=0.6264  , p=0.9868  , df=5\n",
      "parameter F test:         F=0.0888  , p=0.9933  , df_denom=26, df_num=5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: ({'ssr_ftest': (0.8524938095918814, 0.36167367053895305, 38.0, 1),\n",
       "   'ssr_chi2test': (0.9197959524543983, 0.33752855419014605, 1),\n",
       "   'lrtest': (0.9096303357590045, 0.34021252053964746, 1),\n",
       "   'params_ftest': (0.8524938095918764, 0.3616736705389544, 38.0, 1.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x7fd92c330f10>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x7fd92ca20880>,\n",
       "   array([[0., 1., 0.]])]),\n",
       " 2: ({'ssr_ftest': (0.28027810554315613, 0.7572534038858721, 35.0, 2),\n",
       "   'ssr_chi2test': (0.6406356698129282, 0.725918278235963, 2),\n",
       "   'lrtest': (0.635559620623269, 0.7277630166854896, 2),\n",
       "   'params_ftest': (0.28027810554315247, 0.7572534038858751, 35.0, 2.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x7fd92ea5ffd0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x7fd92ec6cd00>,\n",
       "   array([[0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 1., 0.]])]),\n",
       " 3: ({'ssr_ftest': (0.2917772586157381, 0.831007212834428, 32.0, 3),\n",
       "   'ssr_chi2test': (1.0668106018137926, 0.7850915655018633, 3),\n",
       "   'lrtest': (1.0524805078421196, 0.7885560502526318, 3),\n",
       "   'params_ftest': (0.2917772586157339, 0.8310072128344316, 32.0, 3.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x7fd92ec6ce50>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x7fd92ec6ca00>,\n",
       "   array([[0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 4: ({'ssr_ftest': (0.14063120800607876, 0.965693011045074, 29.0, 4),\n",
       "   'ssr_chi2test': (0.737101504031861, 0.9466759621857292, 4),\n",
       "   'lrtest': (0.7300436974708759, 0.9475728922718049, 4),\n",
       "   'params_ftest': (0.14063120800607107, 0.9656930110450777, 29.0, 4.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x7fd92ec6cf40>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x7fd92ec6cc70>,\n",
       "   array([[0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 5: ({'ssr_ftest': (0.0887837426837936, 0.9933491578953649, 26.0, 5),\n",
       "   'ssr_chi2test': (0.6317304767885314, 0.98650439781404, 5),\n",
       "   'lrtest': (0.6263980686526907, 0.9867627160283305, 5),\n",
       "   'params_ftest': (0.08878374268379882, 0.9933491578953638, 26.0, 5.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x7fd92ec6c8e0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x7fd92ec6e070>,\n",
       "   array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run a sample granger test \n",
    "df = df_topics_collection[topics[2]]\n",
    "df = df.rename(columns={\"date\": \"Date\"})\n",
    "df = pd.merge(df, df_all_normalized, on=\"Date\")\n",
    "temp_df = df.loc[(df['Contract'] == 'Rep')]\n",
    "\n",
    "temp_df    \n",
    "\n",
    "res = grangercausalitytests(df[['probability', 'NormalizedPrice']], maxlag=5)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
